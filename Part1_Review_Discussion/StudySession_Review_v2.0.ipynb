{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Deep Learning #\n",
    "## Part 1 : Review Session ##\n",
    "——————————————————————————————————————————"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Chapter 4 : Generative Adversarial Network </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " GAN is a battle between two adversaries, the generator and the discriminator.\n",
    " \n",
    " - Generator\n",
    "   \n",
    "   The generator tries to convert random noise into observations that look as if they have been sampled from the original dataset.\n",
    "   \n",
    " - Discriminator\n",
    " \n",
    "   The discriminator tries to predict whether an observation comes from original dataset or is one of the generator's forgeries.\n",
    "   \n",
    " ![](./imgs/GenDeepLearn_Part1_Review_Pic13.jpg)\n",
    " \n",
    " A simple explanation to the Training Process for GANs\n",
    " \n",
    " - At the beginning\n",
    "   - The generator outputs noisy images and the discriminator predicts randomly.\n",
    " - Generator Learning\n",
    "   - It should be able to fool the detector from identify whether the generated image is brought by a generator or reallife \n",
    " - Discriminator Learning\n",
    "   - Works with the objective to perform successful discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Discriminator </h3>\n",
    " \n",
    "A discriminator is basically a supervised learning convolutional neural network, whose objective is to distinguish whether the generated image is \"fake\" or \n",
    "\"real\". The original paper on GANs (Ian Goodfellow) had a discriminator which was a dense connected ANN, however, now almost all the time a convolutional networks are used. They are also called **DCGAN - Deep Convolutional Generative Adversarial Networks**.\n",
    "\n",
    "Obviously, there is nothing unique about the discriminator and looks like a very similar a standard CNN models. Below is an example.\n",
    "\n",
    "![](./imgs/GenDeepLearn_Part1_Review_Pic14.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Generator </h3>\n",
    "Once again, the generator looks very similar to a **Decoder - VAE (Variational Auto-Encoder)**, which has\n",
    "\n",
    "- INPUT : A vector drawn from a multi-variate normal distribution\n",
    "- OUTPUT : An image (3 channel), built using the input vector and using **Conv2DTranspose** layers to bring to a 2 channel image.\n",
    "\n",
    "**Caveat - Upsampling2D layer**\n",
    "\n",
    "In Keras, we can also use Upsampling2D layer, which works similar to Conv2DTranspose layer. The only different is that, in Conv2DTranspose, 0 (zero) is filled around the original matrix to expand the channel, however, in Upsampling2D, rows and columns are repeated around the original matrix to expand the channel.\n",
    "\n",
    "Both the methods are acceptable in GANs generator networks. Experiments have shown that using Conv2DTranspose leads to formation of checkered patterns, and sometime do not give good clarity to images. However, Upsampling2D also has its own challenges, the ides should be to use both to see which is best for a problem statement.\n",
    "\n",
    "An example of generator network\n",
    "\n",
    "![](./imgs/GenDeepLearn_Part1_Review_Pic15.jpg)\n",
    "\n",
    "Note the peculiar way in which Upsampling2D and std Conv2D layers have been stacked to extract features for good generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training GANs </h3>\n",
    "Training the discriminator is not a unique job, as it is a supervised learning algorithm, where in we provide \"real\" images with label \"1\" and fake images generated by *Generator* with label \"0\". \n",
    "\n",
    "Training the generator is a more difficult job, because we do not know where a *TRUE* image gets mapped on the latent space (lower dimension space). \n",
    "\n",
    "<b style=\"color:blue\">Remember, the objective of the generator is to output images through which it could fool the discriminator, that is, the output of the discriminator for generated images should be \"1\"</b>\n",
    "\n",
    "<h4> Training the Discriminator </h4>\n",
    "While training the discriminator, the objective is to make the model differentiate between \"real\" images and \"fake/generated\" images. So we train the discriminator model using images sourced from a database, which has actual images, and then we train the discriminator on \"generated\" images from generator.\n",
    "\n",
    "<img src=\"./imgs/GenDeepLearn_Part1_Review_Pic16.jpg\" style=\"align:left\" height=\"40%\" width=\"40%\"></img>\n",
    "\n",
    "<b style=\"color:red\"> QUESTION </b>\n",
    "\n",
    "**Why is that we are training the Discriminator in 2 steps, once with \"good\" images and then with \"fake\" images. Why cant we train on a collection of both \"fake\" + \"good\" together?** - Courtsey Elizabeth\n",
    "\n",
    "<h4> Training the Generator </h4>\n",
    "Now when we are training the generator, following important points need to be considered\n",
    "\n",
    "- When training the generator, we need to freeze the waits of the discriminator. This is done because\n",
    "\n",
    "  - The objective of the generator is to generate images which look as real as possible, that means there labels should be \"1\". Although, the discriminator should be predicting probabilities very very less for these images (As that is the objective of the Discriminator), but the generator should be penalized for not being able to bridge this difference. So please note, the lables for the images generated by generator will be \"1\", as the generator need to learn to bridge the gap between \"1\" and the discriminator's predicted probabilities.\n",
    "  \n",
    "  - If we not freeze the weights of the Discriminator, then its weight would also adjust to bridge gap between predicted probabilties and the \"label = 1\", which we do not want, because this would make the Discriminator learn wrong ability.\n",
    "\n",
    "<img src=\"./imgs/GenDeepLearn_Part1_Review_Pic17.jpg\" style=\"align:left\" height=\"40%\" width=\"40%\"></img>\n",
    "\n",
    "<h4> Combined learning process </h4>\n",
    "We take alternate steps to let the Discriminator learn and then we make the Generator learn. Note when the Generator's learning is going on, the Discriminator weights are frozen.\n",
    "\n",
    "![](./imgs/GenDeepLearn_Part1_Review_Pic18.jpg)\n",
    "\n",
    "<b style=\"color:red\"> IMPORTANT NOTE </b>\n",
    "\n",
    "While training GANs, **the learning rate of Discriminator  > the learning rate of Generator**. The main idea behind this is that your generator is only as good as your discriminator.\n",
    "\n",
    "<h4 style=\"color:blue\"> Discussion within MLT COMMUNITY for learning rate note above </h4>\n",
    "\n",
    "`\n",
    "Some points discussed\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Analyzing the performance and training of GANs </h3>\n",
    "\n",
    "![](./imgs/GenDeepLearn_Part1_Review_Pic19.jpg)\n",
    "\n",
    "- Loss \n",
    "  \n",
    "  - We can see that the loss of Discriminator is continously going down, signifying the as the generator is generating new images, the discriminator is getting stronger and stonger.\n",
    "  - We can also see that the loss for Generator is increasing. Remember, the loss in generator would be calculated against value = 1, because the objective of the generator is to fool the discriminator. Since the discriminator is becoming stronger and stronger, this loss is getting increased. However, the generator's objective was always to bridge this gap, and hence as the discriminator becomes stronger, the generator is also becoming stronger and stronger. Also, note/remember, the learning rate of the discriminator > learning rate of generator.\n",
    "  \n",
    "- Accuracy\n",
    "  \n",
    "  The accuracy graph is almost an inverse of the Loss graph. The accuracy of the discriminator is continously increasing and that of generator is reducing\n",
    "  \n",
    "- Generative ability of the Generator\n",
    "\n",
    "  We can also check the generative ability of the generator, by checking the generated images after specific epochs. We could see that as epochs increase, the generative ability of the generator is also getting better. Lastly, the objective of generator is to not generate a duplicate of real images. This is checked by L1 distance between the generated and real images, and then visually verifying how different are generated images from the closest counter-parts in real dataset.\n",
    "\n",
    "![](./imgs/GenDeepLearn_Part1_Review_Pic20.jpg)\n",
    "  \n",
    "![](./imgs/GenDeepLearn_Part1_Review_Pic21.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> GAN Challenges </h3>\n",
    "\n",
    " - Oscillating Loss\n",
    " \n",
    " - Mode Collapse\n",
    " \n",
    " - Uninformative Loss\n",
    " \n",
    " - Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Different types of GANs</h3>\n",
    "\n",
    " - Wasserstein GAN\n",
    " \n",
    " - The Lipschitz Constraint\n",
    " \n",
    " - Weight Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training WGAN </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Analyzing WGAN </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> WGAN-GP </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Analyzing WGAN-GP </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
